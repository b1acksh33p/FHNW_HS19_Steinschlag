{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berechnung eines Steinschlags an der Kantonsstrasse in Schiers (Kt. GR) \n",
    "   In der folgenden Berechnung wird anhand der Daten der letzten drei Monate die Wahrscheinlichkeit \n",
    "   berechnet für einen tödlichen Steinschlag auf der Strasse. Anhand dessen wird ausgesagt \n",
    "   ob die Strasse gesperrt werden muss oder nicht.\n",
    "   Wird die Strasse gesperrt wird untersucht ob diese den ganzen Tag gesperrt bleibt \n",
    "   oder nur für eine gewisse Zeit am Tag\n",
    "\n",
    "### Annahmen:\n",
    "1. Die Ablösungszonen 1 und 2 befinden sich an zwei verschiedenen Stellen\n",
    "2. Die Steine aus den beiden Ablösungszonen werden mit dem gleichen Netz aufgefangen\n",
    "3. Die Wahrscheinlichkeiten werden pro Stundenfenster berechnet und nicht pro Minute\n",
    "4. Die Verteilung des Verkehrs basiert auf den Erkentnissen des Bundesamtes für Statistik\n",
    "5. Steinmassen die nicht möglich sind, werden auf die nächsthöhere Skalierung gerundet (Schätzfehler)\n",
    "6. Die Distanz der Gefahrenzone beträgt 20 m\n",
    "7. Wenn die Gefahrenzone 20 Meter beträgt, dann muss betrachtet werden wie lange das Auto in der Gefahrenzone ist. \n",
    "8. Die Annahme ist, dass bei einem Kontakt von Auto und Stein ein Todesfall verbucht wird.\n",
    "9. Die Länge des Autos ist 5 m\n",
    "\n",
    "### Berechnungsmodel:\n",
    "Um eine Simulations des Models zu bewerkstelligen müssen die einzelnen Variabeln und deren logische Abhängigkeiten \n",
    "in eine Reihenfolge gebracht werden. Aus dieser Betrachtung sollte sich dann ein Model ergeben welches durch eine \n",
    "Monte Carlo Simulation berechnet werden kann:\n",
    "\n",
    "1. P (kinetische Energie) = Wahrscheinlichkeit Geschwindigkeit des Steins  * Wahrscheinlich Masse des Steins\n",
    "2. P (T bis zum nächsten Abschlag) = Wahrscheinlichkeit des Zeitdeltas\n",
    "3. P (Netz bricht beim ersten Aufprall) = P (kinetische Energie > 1000 kJ)\n",
    "4. P1 (Netz bricht über Zeit) = Wenn Summe Masse der Steine > 2000 kg, dann P (kinetische Energie >= 500 kJ )\n",
    "4. P2 (Netz bricht über Zeit) = Wenn Summe Masse der Steine < 2000 kg, dann P (kinetische Energie >= 1000 kJ )\n",
    "6. Summe (Auto im Zeitfenster) = Summe der Menge der Autos in den Zeitfenstern (Leerung + P (Zeitdelta)  \n",
    "7. Aufenthaltsdauer 1 Autos in Gefahrenzone = Distanz / Geschwindigkeit\n",
    "\n",
    "Das Zusammensetzen der einzelnen Wahrscheinlichkeiten wird in einer Monte Carlo Simulation durch Zufallsvariablen \n",
    "simuliert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import random\n",
    "from fitter import Fitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Daten einlesen, säubern und in eine einheitliche Form bringen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Daten laden\n",
    "raw_data_1 = pd.read_csv(\"out_1.csv\")\n",
    "raw_data_2 = pd.read_csv(\"out_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Überprüfen wie viele \"NA\" Werte noch vorhanden sind\n",
    "raw_data_1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_data_2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Alle Zeilen löschen die in ALLEN Zellen keine Werte haben\n",
    "data_1_no_rows = raw_data_1.dropna(how='all')\n",
    "data_2_no_rows = raw_data_2.dropna(how='all')\n",
    "\n",
    "# Alle Kolonen löschen die NA Werte enthalten\n",
    "data_1_no_na = data_1_no_rows.dropna(axis= 'columns')\n",
    "data_2_no_na = data_2_no_rows.dropna(axis= 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Um eine Vergleichbarkeit von Daten herstellen zu können sollte die Benennung der Zellen die selbe sein\n",
    "data_stelle_1= data_1_no_na.rename(columns= {'Datum':'Date',\n",
    "                                             'Uhrzeit': 'Time',\n",
    "                                             'Masse [kg]' : 'Masse in kg' ,\n",
    "                                             'Geschwindigkeit [m/s]' : 'Speed in m/s' \n",
    "                                            })\n",
    "\n",
    "data_stelle_2= data_2_no_na.rename(columns= {'Uhrzeit': 'Time',\n",
    "                                             'm [kg]' : 'Masse in kg' ,\n",
    "                                             'v [m/s]' : 'Speed in m/s' \n",
    "                                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Überprüfen wie viele \"NA\" Werte noch vorhanden sind nachdem auch die Anpassung der Benennungen durchgeführt worden ist\n",
    "data_stelle_1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stelle_2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Zeit und Datum in eine Spalte bringen und in ein Datetime Object transformieren\n",
    "data_stelle_1 ['Datetime'] = pd.to_datetime(data_stelle_1 ['Date'] + \" \" + data_stelle_1 ['Time'])\n",
    "data_stelle_2 ['Datetime'] = pd.to_datetime(data_stelle_2 ['Date'] + \" \" + data_stelle_2 ['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Die beiden Spalten 'Date' und 'Time' werden nicht mehr benötigt und werden gelöscht\n",
    "data_stelle_1 = data_stelle_1.drop('Time', axis=1)\n",
    "data_stelle_1 = data_stelle_1.drop('Date', axis=1)\n",
    "\n",
    "data_stelle_2 = data_stelle_2.drop('Time', axis=1)\n",
    "data_stelle_2 = data_stelle_2.drop('Date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Datetime nach Zeit sortieren\n",
    "data_stelle_2.sort_values(by= ['Datetime'])\n",
    "data_stelle_1.sort_values(by= ['Datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hinzufügen und Berechnung von fehlenden Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# Berechnung der Zeit zwischen den einzelnen Steinschlägen. \n",
    "# Die Anzahl Differenzen beläuft sich auf Anzahl Beobachtungen - 1, da der Startpunkt nicht berücksichtig werden kann\n",
    "\n",
    "# Zeitdifferenzen Abschlagstelle 1\n",
    "t_delta_stelle_1 = []\n",
    "for x in range (len(data_stelle_1['Datetime'])):\n",
    "    try:\n",
    "        delta = int(abs(data_stelle_1 ['Datetime'] [x] - data_stelle_1 ['Datetime'] [x+1]).total_seconds() / 3600)\n",
    "        t_delta_stelle_1.append(delta)   \n",
    "    except:\n",
    "        pass   \n",
    "\n",
    "# Zeitdifferenzen Abschlagstelle 2\n",
    "t_delta_stelle_2 = []\n",
    "for x in range (len(data_stelle_2['Datetime'])):\n",
    "    try:\n",
    "        delta = int(abs(data_stelle_2 ['Datetime'] [x] - data_stelle_2 ['Datetime'] [x+1]).total_seconds() / 3600)\n",
    "        t_delta_stelle_2.append(delta)   \n",
    "    except:\n",
    "        pass   \n",
    "    \n",
    "# Liste in Pandas DataFrame Objekt transformieren\n",
    "t_delta_stelle_1 = pd.DataFrame(t_delta_stelle_1, columns = ['Delta'])\n",
    "t_delta_stelle_2 = pd.DataFrame(t_delta_stelle_2, columns = ['Delta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Die Masse der Steine muss immer > 0 sein, da die Masse im vornherein \n",
    "# geschätzt wurde können 0 KG Steine aufgerundet werden \n",
    "data_stelle_2 ['Datetime'] .where(data_stelle_2 ['Masse in kg'] == 0)\n",
    "\n",
    "# Wie zu sehen ist am 2019-03-10 16:00:00 (Zeile 23) ein Stein mit der Masse 0 Kg ins Netz gefallen. \n",
    "# Diese Masse wird auf 1 kg angepasst\n",
    "data_stelle_2.at [23, 'Masse in kg'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Verteilung des Verkehrs über die Zeit. Dafür werden die Daten des Bundesamts für Statstik herangezogen.\n",
    "#Credit geht hier an Roman Studer, der die Daten vom Bundesamt für Statistik besorgt hat\n",
    "\n",
    "traffic = pd.read_excel(\"traffic.xlsx\")\n",
    "\n",
    "# Normierungfaktors um die percentile auf 1 zu bringen\n",
    "traffic_factor = 1 / (traffic['percentile'].sum() / 100) \n",
    "\n",
    "# Multiplikation der Kolone um die Normierung zu erhalten\n",
    "traffic['percentile'] *= traffic_factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Datenanalyse - Welche Verteilung liegt in den einzelnen Datensätzen vor?\n",
    "Vorgehen: Zuerst werden Histogramme der einzelnen Variabeln erstellet um einen ersten Rückschluss auf die Verteilung \n",
    "zu machen. Ein QQ Plot wird herangezogen um eine zweite Stufe der Analyse durchzuführen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Histogramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Erstelle die Histogramme für alle 6 Verteilungen\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(14, 20))\n",
    "ax0, ax1, ax2, ax3, ax4, ax5 = axes.flatten()\n",
    "\n",
    "\n",
    "# Masse\n",
    "ax0.hist(data_stelle_1['Masse in kg'], \n",
    "         bins = 20, density = True, \n",
    "         histtype = 'bar', color = 'forestgreen',\n",
    "         edgecolor='white', linewidth=0.4,\n",
    "         label = 'Masse 1' )\n",
    "\n",
    "ax1.hist(data_stelle_2['Masse in kg'], \n",
    "         bins = 20, density = True, \n",
    "         histtype = 'bar', color = 'forestgreen',\n",
    "         edgecolor='white', linewidth=0.4,\n",
    "         label = 'Masse 2' )\n",
    "\n",
    "# Geschwindigkeit\n",
    "ax2.hist(data_stelle_1['Speed in m/s'], \n",
    "         bins = 22, density = True, \n",
    "         histtype = 'bar', color = 'skyblue',\n",
    "         edgecolor='white', linewidth=0.4,\n",
    "         label = 'Speed 1' )\n",
    "\n",
    "ax3.hist(data_stelle_2['Speed in m/s'], \n",
    "         bins = 22, density = True, \n",
    "         histtype = 'bar', color = 'skyblue',\n",
    "         edgecolor='white', linewidth=0.4,\n",
    "         label = 'Speed 2' )\n",
    "\n",
    "# Zeitdelta\n",
    "ax4.hist(t_delta_stelle_1 ['Delta'], \n",
    "         bins = 50, density = True, \n",
    "         histtype = 'bar', color = 'darksalmon',\n",
    "         edgecolor='white', linewidth=0.4,\n",
    "         label = 'Zeitdelta 1' )\n",
    "\n",
    "ax5.hist(t_delta_stelle_2 ['Delta'], \n",
    "         bins = 15, density = True, \n",
    "         histtype = 'bar', color = 'darksalmon',\n",
    "         edgecolor='white', linewidth=0.4,\n",
    "         label = 'Zeitdelta 2' )\n",
    "\n",
    "\n",
    "ax0.set_title(\"Histogramm der Masse - Stelle 1\")\n",
    "ax0.set_ylabel(\"Anzahl Ablösungen (normiert)\")\n",
    "ax0.set_xlabel(\"Masse in kg\") \n",
    "ax0.spines['top'].set_visible(False)\n",
    "ax0.spines['right'].set_visible(False)\n",
    "ax0.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "\n",
    "ax1.set_title(\"Histogramm der Masse - Stelle 2\")\n",
    "ax1.set_ylabel(\"Anzahl Ablösungen (normiert)\")\n",
    "ax1.set_xlabel(\"Masse in kg\")\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "\n",
    "ax2.set_title(\"Histogramm der Geschwindigkeit - Stelle 1\")\n",
    "ax2.set_ylabel(\"Anzahl Ablösungen (normiert)\")\n",
    "ax2.set_xlabel(\"Geschwindigkeit in m/s\")\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "\n",
    "ax3.set_title(\"Histogramm der Geschwindigkeit - Stelle 2\")\n",
    "ax3.set_ylabel(\"Anzahl Ablösungen (normiert)\")\n",
    "ax3.set_xlabel(\"Geschwindigkeit in m/s\")\n",
    "ax3.spines['top'].set_visible(False)\n",
    "ax3.spines['right'].set_visible(False)\n",
    "ax3.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "\n",
    "ax4.set_title(\"Histogramm des Zeitdeltas - Stelle 1\")\n",
    "ax4.set_ylabel(\"Anzahl Ablösungen (normiert)\")\n",
    "ax4.set_xlabel(\"Zeitdelta in Stunden\")\n",
    "ax4.spines['top'].set_visible(False)\n",
    "ax4.spines['right'].set_visible(False)\n",
    "ax4.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "\n",
    "ax5.set_title(\"Histogramm des Zeitdeltas - Stelle 1\")\n",
    "ax5.set_ylabel(\"Anzahl Ablösungen (normiert)\")\n",
    "ax5.set_xlabel(\"Zeitdelta in Stunden\")\n",
    "ax5.spines['top'].set_visible(False)\n",
    "ax5.spines['right'].set_visible(False)\n",
    "ax5.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Erkenntnis\n",
    "\n",
    "Nachdem ersten Einblick in die Daten und Histogramme ist zu sehen das wir mehrere Verteilungen erwarten können. \n",
    "Bei der Geschwindigkeit wird es sich höchstwahrscheinlich um eine normalverteilte Verteilungen handeln, \n",
    "wohingegen bei den anderen weitere Untersuchungen durchgeführt werden müssen um Sicherheit zu gewinnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# QQ - Plot Geschwindigkeit Stelle 1\n",
    "\n",
    "plt.figure(figsize=(8, 8), dpi=80)\n",
    "stats.probplot(data_stelle_1['Speed in m/s'], dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot - Speed in m/s Stelle 1\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# QQ - Plot Geschwindigkeit Stelle 2\n",
    "\n",
    "plt.figure(figsize=(8, 8), dpi=80)\n",
    "stats.probplot(data_stelle_2['Speed in m/s'], dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot - Speed in m/s Stelle 2\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Erkenntnis Geschwindigkeit\n",
    "Bei der Gecshwindigkeit 1 ist schön zu beobachten, dass es keine nennenswerte Abweichungen auf dem QQ Plot zu \n",
    "erkennen gibt, damit kann die Hypothese von weiter oben, dass es sich um eine Normalverteilung handelt, weiterhin beibehalten werden. \n",
    "Im Fall der Geschwindigkeit 2 sollte definitiv noch einmal tiefer ins Detail gegangen werden, da die Abweichungen grösser als die erwarteten bei einer Normalverteilung sind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# QQ - Plot Masse Stelle 1\n",
    "\n",
    "plt.figure(figsize=(8, 8), dpi=80)\n",
    "stats.probplot(data_stelle_1['Masse in kg'], dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot - Msse in kg Stelle 1\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# QQ - Plot Masse Stelle 2\n",
    "\n",
    "plt.figure(figsize=(8, 8), dpi=80)\n",
    "stats.probplot(data_stelle_2['Masse in kg'], dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot - Masse in kg Stelle 2\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Erkenntnis Masse\n",
    "Wie weiter oben schon erkannt, handelt es sich hier definitiv nicht um eine Normalverteilung.\n",
    "Was weiter noch erkennbar ist: \n",
    "- die Werte sind nicht <0\n",
    "- rechtsschief\n",
    "- heavy tails (schwere Ränder) nach oben\n",
    "- starke Konzentration um den Median (Stelle 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# QQ - Plot Zeitdelta Stelle 1\n",
    "\n",
    "plt.figure(figsize=(8, 8), dpi=80)\n",
    "stats.probplot(t_delta_stelle_1['Delta'], dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot - Zeitdelta Stelle 1\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# QQ - Plot Zeitdelta Stelle 2\n",
    "\n",
    "plt.figure(figsize=(6, 6), dpi=80)\n",
    "stats.probplot(t_delta_stelle_2['Delta'], dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot - Zeitdelta Stelle 2\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Erkenntnis Zeitdelta\n",
    "- rechtsschief\n",
    "- heavy tails (schwere Ränder) - noch extremer als bei der Geschwindigkeit\n",
    "- Gaps bei Zeitdelta 1 beim 1. Quantil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weiteres Vorgehen\n",
    "Da es sich nicht eindeutig definieren lässt welche Verteilungen zugrunde liegen werden im nächsten Schritt 80 verschiedene Verteilungen auf ihre mögliche Passgenauigkeit überprüft. Das Beurteilungskrieterium ist der statistische Fehler. Je kleiner der Fehler dest besser passt die Verteilung.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fitting der Daten\n",
    "Nach dem Fitten sollte für jeden Datensatz eine Verteilung mit den dazugehörigen Parametern verfügbar sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fitten der Daten Masse Ablösestelle 1\n",
    "fit_masse_1 = Fitter(data_stelle_1['Masse in kg'], distributions=['beta','lognorm', \n",
    "                                                                  'gamma', 'expon',\n",
    "                                                                  'norm'])\n",
    "\n",
    "fit_masse_1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8), dpi=80)\n",
    "fit_masse_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fitten der Daten Masse Ablösestelle 2\n",
    "fit_masse_2 = Fitter(data_stelle_2['Masse in kg'], distributions=['lognorm', 'gamma', 'expon',\n",
    "                                                                  'beta', 'triang', 'norm'])\n",
    "\n",
    "\n",
    "fit_masse_2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8), dpi=80)\n",
    "fit_masse_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fitten der Daten Geschwindigkeit Ablösestelle 1\n",
    "fit_speed_1 = Fitter(data_stelle_1['Speed in m/s'], distributions=['lognorm', 'gamma', 'expon',\n",
    "                                                                  'triang', 'norm'])\n",
    "\n",
    "fit_speed_1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8), dpi=80)\n",
    "fit_speed_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fitten der Daten Geschwindigkeit Ablösestelle 2\n",
    "fit_speed_2 = Fitter(data_stelle_2['Speed in m/s'], distributions=['lognorm', 'gamma', 'expon',\n",
    "                                                                  'triang', 'norm'])\n",
    "\n",
    "\n",
    "fit_speed_2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8), dpi=80)\n",
    "fit_speed_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fitten der Daten Zeitdelta Ablösestelle 1\n",
    "fit_t_delta_1 = Fitter(t_delta_stelle_1['Delta'], distributions=['lognorm', 'gamma', 'expon',\n",
    "                                                                  'triang', 'norm'])\n",
    "\n",
    "fit_t_delta_1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8), dpi=80)\n",
    "fit_t_delta_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitten der Daten Zeitdelta Ablösestelle 2\n",
    "fit_t_delta_2 = Fitter(t_delta_stelle_2['Delta'], distributions=['lognorm', 'gamma', 'expon',\n",
    "                                                                  'triang', 'norm'])\n",
    "\n",
    "fit_t_delta_2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8), dpi=80)\n",
    "fit_t_delta_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. Zufalsvariabeln definieren\n",
    "Nachdem die Art der Verteilungen eruiert worden sind, kann im nächsten Schritt ein Zufallsvariabelngenerator definiert werden als Vorbereitung für die Monte Carlo Simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_masse_1.fitted_param['expon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masse_1_shape = 12.0\n",
    "masse_1_scale = 616.6323529411765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_masse_2.fitted_param['expon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masse_2_shape = 1\n",
    "masse_2_scale = 98.28125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_speed_1.fitted_param['norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_1_mu = 8.788235294117646\n",
    "speed_1_std = 1.9745088303442118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_speed_2.fitted_param['norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_2_mu = 37.790625\n",
    "speed_2_std = 5.31080027956004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_t_delta_1.fitted_param['gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t_1_shape = 0.7720943018929209\n",
    "delta_t_1_scale = 32.180388904581854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_t_delta_2.fitted_param['gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t_2_shape = 0.6924339239082432\n",
    "delta_t_2_scale = 85.33142881264439"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_masse_1():\n",
    "    masse_1 = round(np.random.exponential(masse_1_scale),2)\n",
    "    return masse_1\n",
    "\n",
    "def random_masse_2():\n",
    "    masse_2 = round(np.random.exponential(masse_2_scale),2)\n",
    "    return masse_2\n",
    "\n",
    "def random_speed_1():\n",
    "    speed_1 = round(np.random.normal(speed_1_mu, speed_1_std),2)\n",
    "    return speed_1\n",
    "\n",
    "def random_speed_2():\n",
    "    speed_2 = round(np.random.normal(speed_2_mu, speed_2_std),2)\n",
    "    return speed_2\n",
    "\n",
    "def random_t_delta_1():\n",
    "    t_delta_1 = round(np.random.gamma(delta_t_1_shape, delta_t_1_scale))\n",
    "    return t_delta_1\n",
    "\n",
    "def random_t_delta_2():\n",
    "    t_delta_2 = round(np.random.gamma(delta_t_2_shape, delta_t_2_scale))\n",
    "    return t_delta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random_speed_1()\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Erkenntnisse Fitting\n",
    "Wie vorausgesagt haben wir einerseits mehrere Vertielungen gesehen, andernseits hat sich auch bestätigt, dass die Gaussische Normalverteilung in den Geschwindigkeiten wiederspiegelt.\n",
    "Die oben definierten Zufallsgeneratoren für die Zahlen Geschwindigkeit, Masse und Zeitdelta werden in der Monte Carlo Simulation verwendet um 100 Jahre der Simulation durchführen zu können.\n",
    "\n",
    "DISCLAIMER I: SciPy hat 80 verschiedene Distributionen die getestet werden können. aus Komplexitätsgründen wurde dabei nur ein Teil ausgewählt.\n",
    "DISCLAIMER II: Die Beschriftung der Fitting Outputs (Plot mit Histogramm und Probability Density Function) war in diesem Fall nicht möglich, Ziel wäre es gewesen alle Plots zu beschriften. Dieses Ziel konnte hier nicht erreich werden.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6. Monte Carlo berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "header = ['Hours', 'Day', 'M 1', 'Speed 1', 'M 2', 'Speed 2', 'E in kJ 1', 'E in kJ 2', 'Sum M', 'Breakthrough']\n",
    "all_breakthroughs = pd.DataFrame( columns = header )\n",
    "\n",
    "for x in range (100):\n",
    "    \n",
    "    # Kreieren von Leeren Listen um die Resultate zu sammeln\n",
    "    results = []\n",
    "    double_entries = []\n",
    "\n",
    "    # Definition der Betrachtungsdauer für die Monte Carlo\n",
    "    # 100 Jahre * 365 Tage * 24 Stunden = 8760 Stunden\n",
    "\n",
    "    amount_of_hours = 876000\n",
    "\n",
    "    # Kreiere eine Liste um die die Resultate darin abzufüllen\n",
    "    for i in range (0, amount_of_hours, 1):\n",
    "        results.append(i)\n",
    "\n",
    "    for i in range (0, amount_of_hours, 1):\n",
    "        double_entries.append(i)\n",
    "\n",
    "    # Transformation in ein Pandas DataFrame Object    \n",
    "    results = pd.DataFrame(results, columns= ['Hours'])\n",
    "    double_entries = pd.DataFrame(double_entries, columns= ['Hours'])\n",
    "\n",
    "    # Definition der benötigten Spalten\n",
    "    header = ['Day', 'Hour of Day', 'M 1', 'Speed 1', 'M 2', 'Speed 2', 'E in kJ 1', 'E in kJ 2', 'Sum M', 'Breakthrough']\n",
    "\n",
    "    # Hinzufügen aller Spalten ins DataFrame Object und befülle mit NaN Werten\n",
    "    for value in header:\n",
    "        results[value] = np.nan\n",
    "\n",
    "    for value in header: \n",
    "        double_entries[value] = np.nan\n",
    "\n",
    "    # Start- und Endpunkt für die Monte Carlo Simulation\n",
    "    end = amount_of_hours\n",
    "    start = 0\n",
    "\n",
    "    # Iterationsschritt für Masse und Geschwindigkeit\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    # Fortlaufender Zähler der Zeit des Abschlags\n",
    "    event_1 = 0\n",
    "    event_2 = 0\n",
    "\n",
    "\n",
    "    # Berechnungen der Zufallsvariablen in der Monte Carlo Simulation\n",
    "    # Im ersten Schritt wird das Zeitdelta berechnet, ist das Zeitdelta > 0 dann wird die Masse und die Geschwindigkeit \n",
    "    # als Zufallsvariable berechnet. Dabei wird die Funktion von weiter oben abgerufen. Im letzten Schritt werden Masse \n",
    "    # und Geschwindigkeit zum Zeitpunkt \"event_X\" im DataFrame Objekt gespeichert. \n",
    "\n",
    "    # Kommt es dazu, dass ein Event zur gleichen Zeit zwei Mal vorkommt (2 Abschläge im gleichen Zeitenster, dann wird dies im \n",
    "    # DataFrame \"double_entries\" abgespeichert (Bedingung t_delta_X = 0)\n",
    "\n",
    "    while i < end:\n",
    "        t_delta_1 = random_t_delta_1()\n",
    "\n",
    "        if t_delta_1 > 0:        \n",
    "            event_1 += t_delta_1\n",
    "\n",
    "            masse_1 = random_masse_1()\n",
    "            results['M 1'][event_1] = masse_1\n",
    "\n",
    "            speed_1 = random_speed_1()\n",
    "            results['Speed 1'][event_1] = speed_1\n",
    "            i += t_delta_1\n",
    "\n",
    "        else: \n",
    "            masse_1 = random_masse_1()\n",
    "            double_entries['M 1'][event_1] = masse_1\n",
    "\n",
    "            speed_1 = random_speed_1()\n",
    "            double_entries['Speed 1'][event_1] = speed_1\n",
    "\n",
    "    while j < end:\n",
    "        t_delta_2 = random_t_delta_2()\n",
    "\n",
    "        if t_delta_2 > 0:\n",
    "            event_2 += t_delta_2\n",
    "\n",
    "            masse_2 = random_masse_2()\n",
    "            results['M 2'][event_2] = masse_2\n",
    "\n",
    "            speed_2 = random_speed_2()\n",
    "            results['Speed 2'][event_2] = speed_2\n",
    "            j += t_delta_2\n",
    "\n",
    "        else:\n",
    "            masse_2 = random_masse_2()\n",
    "            double_entries['M 2'][event_2] = masse_2\n",
    "\n",
    "            speed_2 = random_speed_2()\n",
    "            double_entries['Speed 2'][event_2] = speed_2 \n",
    "\n",
    "\n",
    "    # Da es wenige Ereignisse gibt die im gleichen Zeitfenster geschehen, können die überflüssigen Zeilen rausgefiltert \n",
    "    # werden\n",
    "\n",
    "    filtered_double_entries = double_entries.dropna(thresh = 2)\n",
    "\n",
    "    # Tabelle zusammenfügen, bereinigen und auffüllen\n",
    "\n",
    "    frames = [results, filtered_double_entries]\n",
    "    all_data = pd.concat(frames)\n",
    "\n",
    "    all_data = all_data.sort_values(by = ['Hours'] )\n",
    "\n",
    "    all_data = all_data.fillna(0)\n",
    "\n",
    "    all_data = all_data.reset_index(drop = True)\n",
    "\n",
    "    # Berechnung fehlenden Felder\n",
    "\n",
    "    # Formel für kinetische Energie verwenden\n",
    "    all_data['E in kJ 1'] = all_data.apply(lambda x: all_data['M 1'] * all_data['Speed 1'] * all_data['Speed 1'] / 2 / 1000)\n",
    "    all_data['E in kJ 2'] = all_data.apply(lambda x: all_data['M 2'] * all_data['Speed 2'] * all_data['Speed 2'] / 2 / 1000)\n",
    "\n",
    "    # Berechnung des Tages um eine bessere Kotrolle im Enddokument vornehmen zu können\n",
    "    all_data['Day'] = all_data.apply(lambda x: all_data['Hours'] // 24)\n",
    "\n",
    "    # Berechnung der Stunde des Tages um eine bessere Kontrolle im Enddokument vornehmen zu können\n",
    "    all_data['Hour of Day'] = all_data.apply(lambda x: all_data['Hours'] % 24)\n",
    "\n",
    "    # In diesem Schritt werden die Steine alle 24 Stunden geleert. Um dies zu bewerkstelligen, werden zur Stunde 0 die \n",
    "    # Summen in den Netzen geleert und ansonsten immer mit dem vorherigen Element gefüllt.\n",
    "\n",
    "    INDEX = 0\n",
    "    end = all_data['Hours'].iloc[-1]\n",
    "    sum_M = 0\n",
    "\n",
    "    while INDEX <= end:\n",
    "\n",
    "        modulo = all_data['Hours'][INDEX] % 24\n",
    "\n",
    "        if modulo != 0:\n",
    "            sum_M += all_data['M 1'][INDEX] + all_data['M 2'][INDEX]\n",
    "\n",
    "            all_data['Sum M'][INDEX] = sum_M\n",
    "\n",
    "            INDEX += 1\n",
    "\n",
    "        else:\n",
    "            sum_M = all_data['M 1'][INDEX] + all_data['M 2'][INDEX]\n",
    "            all_data['Sum M'][INDEX] = sum_M\n",
    "            INDEX += 1\n",
    "\n",
    "    # Im nächsten Schritt wird beurteilt ob der runtergefallene Stein einen Durchbruch im Netz hervorruft. Ist dies der \n",
    "    # Fall, dann wird in der Zelle \"Breakthrough\" eine 1 ( = True) geschrieben, ansonsten eine 0 ( = False)\n",
    "\n",
    "    INDEX = 0\n",
    "    end = all_data['Hours'].iloc[-1]\n",
    "\n",
    "    while INDEX < end:\n",
    "\n",
    "        if all_data['Hour of Day'][INDEX] == 0:\n",
    "\n",
    "            if (all_data['E in kJ 1'][INDEX] or all_data['E in kJ 2'][INDEX]) >= 1000:\n",
    "                all_data['Breakthrough'][INDEX] = 1\n",
    "\n",
    "                while True:\n",
    "                    INDEX += 1\n",
    "\n",
    "                    if all_data['Hour of Day'][INDEX] == 0:\n",
    "                        break\n",
    "\n",
    "            else:\n",
    "                INDEX += 1\n",
    "\n",
    "        else:\n",
    "            if all_data['Sum M'][INDEX-1] < 2000:\n",
    "\n",
    "                if (all_data['E in kJ 1'][INDEX] or all_data['E in kJ 2'][INDEX]) >= 1000:\n",
    "                    all_data['Breakthrough'][INDEX] = 1\n",
    "\n",
    "                    while True:\n",
    "                        INDEX += 1\n",
    "\n",
    "                        if all_data['Hour of Day'][INDEX] == 0:\n",
    "                            break\n",
    "\n",
    "                else:\n",
    "                    INDEX += 1\n",
    "\n",
    "\n",
    "            elif all_data['Sum M'][INDEX-1] > 2000:\n",
    "\n",
    "                if (all_data['E in kJ 1'][INDEX] or all_data['E in kJ 2'][INDEX]) >= 500:\n",
    "                    all_data['Breakthrough'][INDEX] = 1\n",
    "\n",
    "                    while True:\n",
    "                        INDEX += 1\n",
    "\n",
    "                        if all_data['Hour of Day'][INDEX] == 0:\n",
    "                            break\n",
    "\n",
    "                else:\n",
    "                    INDEX += 1\n",
    "\n",
    "    # Speichere das Dokument ab\n",
    "    writer = pd.ExcelWriter('output_per_hour.xlsx') \n",
    "    all_data.to_excel(writer)\n",
    "    writer.save()\n",
    "\n",
    "    # Kreiere ein Subset der Breakthroughs und speichere das Dokument um es später wieder verwenden zu können\n",
    "\n",
    "    subset = all_data[(all_data['Breakthrough'] > 0)]\n",
    "    if len(subset)>0:\n",
    "        print ('yes')\n",
    "    else:\n",
    "        print('no')\n",
    "        \n",
    "    all_breakthroughs = all_breakthroughs.append (subset, ignore_index=True)\n",
    "    \n",
    "writer = pd.ExcelWriter('all_breakthroughs.xlsx') \n",
    "all_breakthroughs.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('breakthrough.xlsx') \n",
    "subset.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 7. Berechnung ob ein Fahrzeug getroffen wird wenn das Netz bricht\n",
    "\n",
    "Um die Zeit in der Gefahrenzone zu berechnen, wird die Anzahl Fahrzeuge im Zeitfenster mit der Zeit im Zeitfenster \n",
    "multipliziert. die Zeit pro Fahrzeug in der Gefahrenzone wird berechnet mit der Geschwindigkeit und der Länge der \n",
    "Gefahrenzone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "breakthrough = pd.read_excel('breakthrough.xlsx')\n",
    "verteilung_verkehr = pd.read_excel ('traffic.xlsx')\n",
    "\n",
    "breakthrough\n",
    "\n",
    "# In der MonteCarlo Simulation haben wir als Betrcahtungzeitraum 100 Jahre definiert. Dies entspricht 876000 Stunden\n",
    "Stunden = amount_of_hours\n",
    "\n",
    "# Aus \"breakthrough\" brauchen wir nur die Stunde und den %-ualen Aneile der Fahrzeuge um berechnen zu können wie \n",
    "# viele Fahrzeuge und wie lange diese in der Gefahrenzone sind.\n",
    "\n",
    "# Wenn die Gefahrenzone 20 Meter beträgt, dann muss betrachtet werden wie lange das Auto in der Gefahrenzone ist. \n",
    "# Die Annahme ist, dass bei einem Kontakt von Auto und Stein ein Todesfall verbucht wird.\n",
    "# Die Länge des Autos ist 5 m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "anz_unfälle = all_breakthroughs.drop(columns = ['Hours', 'Day', \n",
    "                                       'M 1', 'Speed 1', 'M 2', 'Speed 2',\n",
    "                                       'E in kJ 1', 'E in kJ 2', 'Sum M',\n",
    "                                       'Breakthrough'])\n",
    "\n",
    "anz_unfälle ['Anz_Fahrz'] = np.nan\n",
    "anz_unfälle ['t_event_danger'] = np.nan\n",
    "anz_unfälle ['Todesfall'] = np.nan\n",
    "verteilung_verkehr ['Anz_Fahrz'] = np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "länge_gefahrenzone = 0.300\n",
    "fahrzeug_speed = 60\n",
    "total_fahrzeuge_tag = 1200\n",
    "\n",
    "t_danger_zone = länge_gefahrenzone / fahrzeug_speed\n",
    "\n",
    "verteilung_verkehr['Anz_Fahrz'] = verteilung_verkehr.apply(lambda x: verteilung_verkehr['percentile'] / 100 *  1200)\n",
    "\n",
    "verteilung_verkehr.Anz_Fahrz = verteilung_verkehr.Anz_Fahrz.round()\n",
    "verteilung_verkehr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "anz_unfälle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Basierend auf der Stunde des Durchbruchs wird die Anzahl der Fahrzeuge in dieser Stunde hinzugefügt\n",
    "try:\n",
    "    for x in range (0,len(anz_unfälle)):\n",
    "        anz_unfälle ['Anz_Fahrz'][x] = verteilung_verkehr['Anz_Fahrz'][(anz_unfälle['Hour of Day'][x])]\n",
    "\n",
    "# Mit der Anzahl Fahrzeuge kann berechnet werden wie lange Fahrzeuge in der Gefahrenzone bleiben\n",
    "        anz_unfälle['t_event_danger'] = anz_unfälle.apply(lambda x: anz_unfälle['Anz_Fahrz'] * t_danger_zone)\n",
    "    \n",
    "except:\n",
    "    print (\"Es besteht keine Möglichkeit eines Netzdurchbruchs\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', anz_unfälle.shape[0]+1)\n",
    "print(anz_unfälle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def random_time():\n",
    "    random_time = random.random()\n",
    "    return random_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = len(anz_unfälle)\n",
    "TOT = 0\n",
    "for i in range(end):\n",
    "    event_time = random_time()\n",
    "    print (\" event %.3f\" % event_time)\n",
    "    if event_time > anz_unfälle['t_event_danger'][i]:\n",
    "        print (\" danger %.3f\" % anz_unfälle['t_event_danger'][i] )\n",
    "        anz_unfälle['Todesfall'] = 0\n",
    "    \n",
    "    else:\n",
    "        anz_unfälle['Todesfall'] = 1\n",
    "        print (\"tot\")\n",
    "        TOT += 1\n",
    "    \n",
    "print (TOT)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Die Wahrscheinlichkeit für einen Todesfall resultiert aus den Anz. Todesfällen / Anz. Betrachtungen\n",
    "\n",
    "P_Todesfall = TOT / Stunden\n",
    "\n",
    "if P_Todesfall > 0.0001:\n",
    "    print('Die Strasse wird gesperrt')\n",
    "else:\n",
    "    print('Die Strasse wird NICHT gesperrt')\n",
    "print (P_Todesfall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
